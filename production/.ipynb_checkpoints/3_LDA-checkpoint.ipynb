{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5f342b-499a-43c3-af79-3604eb8092ff",
   "metadata": {},
   "source": [
    "# Perform leave-one-out LDA on acoustic measures\n",
    "\n",
    "Input large df with acoustic measures for each vowel in each word and output added accuracy for each acoustic measure of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2a7f760-9a6d-40fd-ab77-8903f49b247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold as kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e8c63895-dfec-4d6c-9996-b29599afe03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>H1c_mean</th>\n",
       "      <th>H2c_mean</th>\n",
       "      <th>H4c_mean</th>\n",
       "      <th>A1c_mean</th>\n",
       "      <th>A2c_mean</th>\n",
       "      <th>A3c_mean</th>\n",
       "      <th>H2Kc_mean</th>\n",
       "      <th>H1H2c_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>t1_wd</th>\n",
       "      <th>t2_wd</th>\n",
       "      <th>word</th>\n",
       "      <th>stress</th>\n",
       "      <th>syl_dur</th>\n",
       "      <th>v_dur</th>\n",
       "      <th>sF1_norm</th>\n",
       "      <th>sF2_norm</th>\n",
       "      <th>pF1_norm</th>\n",
       "      <th>pF2_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lrv099_catala_exp2_a.mat</td>\n",
       "      <td>i</td>\n",
       "      <td>20.927</td>\n",
       "      <td>4.120</td>\n",
       "      <td>-12.382</td>\n",
       "      <td>-21.605</td>\n",
       "      <td>-13.612</td>\n",
       "      <td>-8.504</td>\n",
       "      <td>-14.792</td>\n",
       "      <td>16.808</td>\n",
       "      <td>...</td>\n",
       "      <td>3.056936</td>\n",
       "      <td>3.501372</td>\n",
       "      <td>desanimar</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084149</td>\n",
       "      <td>0.037912</td>\n",
       "      <td>0.646745</td>\n",
       "      <td>2.078281</td>\n",
       "      <td>0.263155</td>\n",
       "      <td>2.079375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lrv099_catala_exp2_a.mat</td>\n",
       "      <td>a</td>\n",
       "      <td>19.418</td>\n",
       "      <td>4.686</td>\n",
       "      <td>-14.122</td>\n",
       "      <td>-19.125</td>\n",
       "      <td>-21.252</td>\n",
       "      <td>-9.591</td>\n",
       "      <td>-11.833</td>\n",
       "      <td>14.732</td>\n",
       "      <td>...</td>\n",
       "      <td>3.056936</td>\n",
       "      <td>3.501372</td>\n",
       "      <td>desanimar</td>\n",
       "      <td>1</td>\n",
       "      <td>0.141372</td>\n",
       "      <td>0.080206</td>\n",
       "      <td>0.764094</td>\n",
       "      <td>1.375944</td>\n",
       "      <td>0.564352</td>\n",
       "      <td>1.266652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lrv099_catala_exp2_a.mat</td>\n",
       "      <td>i</td>\n",
       "      <td>11.935</td>\n",
       "      <td>15.855</td>\n",
       "      <td>17.809</td>\n",
       "      <td>10.503</td>\n",
       "      <td>4.465</td>\n",
       "      <td>6.305</td>\n",
       "      <td>2.997</td>\n",
       "      <td>-3.920</td>\n",
       "      <td>...</td>\n",
       "      <td>7.674408</td>\n",
       "      <td>8.083331</td>\n",
       "      <td>elimina</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110360</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.198170</td>\n",
       "      <td>2.156112</td>\n",
       "      <td>0.304463</td>\n",
       "      <td>1.997006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lrv099_catala_exp2_a.mat</td>\n",
       "      <td>a</td>\n",
       "      <td>9.754</td>\n",
       "      <td>13.376</td>\n",
       "      <td>22.242</td>\n",
       "      <td>8.334</td>\n",
       "      <td>2.360</td>\n",
       "      <td>13.707</td>\n",
       "      <td>3.894</td>\n",
       "      <td>-3.623</td>\n",
       "      <td>...</td>\n",
       "      <td>7.674408</td>\n",
       "      <td>8.083331</td>\n",
       "      <td>elimina</td>\n",
       "      <td>0</td>\n",
       "      <td>0.103463</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.216104</td>\n",
       "      <td>1.612011</td>\n",
       "      <td>0.418792</td>\n",
       "      <td>1.533985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lrv099_catala_exp2_a.mat</td>\n",
       "      <td>i</td>\n",
       "      <td>22.174</td>\n",
       "      <td>6.194</td>\n",
       "      <td>-8.876</td>\n",
       "      <td>-17.493</td>\n",
       "      <td>-13.925</td>\n",
       "      <td>-14.555</td>\n",
       "      <td>-15.125</td>\n",
       "      <td>15.979</td>\n",
       "      <td>...</td>\n",
       "      <td>12.207800</td>\n",
       "      <td>12.815098</td>\n",
       "      <td>discrimina</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119827</td>\n",
       "      <td>0.059827</td>\n",
       "      <td>0.619651</td>\n",
       "      <td>2.169299</td>\n",
       "      <td>0.267623</td>\n",
       "      <td>2.054012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Filename Label  H1c_mean  H2c_mean  H4c_mean  A1c_mean  \\\n",
       "0  lrv099_catala_exp2_a.mat     i    20.927     4.120   -12.382   -21.605   \n",
       "1  lrv099_catala_exp2_a.mat     a    19.418     4.686   -14.122   -19.125   \n",
       "2  lrv099_catala_exp2_a.mat     i    11.935    15.855    17.809    10.503   \n",
       "3  lrv099_catala_exp2_a.mat     a     9.754    13.376    22.242     8.334   \n",
       "4  lrv099_catala_exp2_a.mat     i    22.174     6.194    -8.876   -17.493   \n",
       "\n",
       "   A2c_mean  A3c_mean  H2Kc_mean  H1H2c_mean  ...      t1_wd      t2_wd  \\\n",
       "0   -13.612    -8.504    -14.792      16.808  ...   3.056936   3.501372   \n",
       "1   -21.252    -9.591    -11.833      14.732  ...   3.056936   3.501372   \n",
       "2     4.465     6.305      2.997      -3.920  ...   7.674408   8.083331   \n",
       "3     2.360    13.707      3.894      -3.623  ...   7.674408   8.083331   \n",
       "4   -13.925   -14.555    -15.125      15.979  ...  12.207800  12.815098   \n",
       "\n",
       "         word  stress   syl_dur     v_dur  sF1_norm  sF2_norm  pF1_norm  \\\n",
       "0   desanimar       0  0.084149  0.037912  0.646745  2.078281  0.263155   \n",
       "1   desanimar       1  0.141372  0.080206  0.764094  1.375944  0.564352   \n",
       "2     elimina       1  0.110360  0.048069  0.198170  2.156112  0.304463   \n",
       "3     elimina       0  0.103463  0.066019  0.216104  1.612011  0.418792   \n",
       "4  discrimina       1  0.119827  0.059827  0.619651  2.169299  0.267623   \n",
       "\n",
       "   pF2_norm  \n",
       "0  2.079375  \n",
       "1  1.266652  \n",
       "2  1.997006  \n",
       "3  1.533985  \n",
       "4  2.054012  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335bcde-b411-4879-ac00-c732b1bec8ec",
   "metadata": {},
   "source": [
    "Check `Label` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "704523df-67f2-430a-9d9c-8b154f2eddbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'a', 'pen', 'ult', 'o'], dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9e01074c-9ce8-413f-a867-f2ca21a9fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[(df['Label']==\"i\") | (df['Label']==\"pen\")].copy()\n",
    "df_2 = df[(df['Label']!=\"i\") & (df['Label']!=\"pen\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9f4e83fa-39e3-475f-a020-658f63c4fdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd = pd.merge(df_1, df_2, on=['Filename', 'word', 't1_wd', 't2_wd', 'partID', 'Language'],\n",
    "                 suffixes=('_vowel1', '_vowel2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b55e6e-3f05-4ec4-948a-5746241c8339",
   "metadata": {},
   "source": [
    "Label row as `Paroxytone` if vowel 1 is stressed and `Oxytone` if vowel 2 is stressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4c3b28a1-ba28-4333-a202-6b5db176e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd['stress_wd'] = np.where(df_wd['stress_vowel1']==1, 'Paroxytone', 'Oxytone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104a87e-4dbc-4c02-8f11-14f004f40ec3",
   "metadata": {},
   "source": [
    "Columns to drop from LDA: `Filename`, `stress_vowel1`, `stress_vowel2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d70fee88-c8e6-4ddc-8f03-b1a0dc23c764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H1c_mean_vowel1</th>\n",
       "      <th>H2c_mean_vowel1</th>\n",
       "      <th>H4c_mean_vowel1</th>\n",
       "      <th>A1c_mean_vowel1</th>\n",
       "      <th>A2c_mean_vowel1</th>\n",
       "      <th>A3c_mean_vowel1</th>\n",
       "      <th>H2Kc_mean_vowel1</th>\n",
       "      <th>H1H2c_mean_vowel1</th>\n",
       "      <th>H2H4c_mean_vowel1</th>\n",
       "      <th>H1A1c_mean_vowel1</th>\n",
       "      <th>...</th>\n",
       "      <th>pF0_mean_vowel2</th>\n",
       "      <th>shrF0_mean_vowel2</th>\n",
       "      <th>epoch_mean_vowel2</th>\n",
       "      <th>syl_dur_vowel2</th>\n",
       "      <th>v_dur_vowel2</th>\n",
       "      <th>sF1_norm_vowel2</th>\n",
       "      <th>sF2_norm_vowel2</th>\n",
       "      <th>pF1_norm_vowel2</th>\n",
       "      <th>pF2_norm_vowel2</th>\n",
       "      <th>stress_wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>11.870</td>\n",
       "      <td>-2.280</td>\n",
       "      <td>-1.756</td>\n",
       "      <td>-5.440</td>\n",
       "      <td>-16.559</td>\n",
       "      <td>-7.019</td>\n",
       "      <td>-17.947</td>\n",
       "      <td>14.150</td>\n",
       "      <td>-0.524</td>\n",
       "      <td>17.311</td>\n",
       "      <td>...</td>\n",
       "      <td>219.476</td>\n",
       "      <td>217.922</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.324093</td>\n",
       "      <td>0.061651</td>\n",
       "      <td>0.491066</td>\n",
       "      <td>1.297863</td>\n",
       "      <td>0.606663</td>\n",
       "      <td>1.605660</td>\n",
       "      <td>Paroxytone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>8.287</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-4.275</td>\n",
       "      <td>-13.221</td>\n",
       "      <td>-11.741</td>\n",
       "      <td>-14.051</td>\n",
       "      <td>-11.644</td>\n",
       "      <td>8.341</td>\n",
       "      <td>4.220</td>\n",
       "      <td>21.508</td>\n",
       "      <td>...</td>\n",
       "      <td>217.179</td>\n",
       "      <td>219.021</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.251639</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>1.852478</td>\n",
       "      <td>0.285118</td>\n",
       "      <td>1.676987</td>\n",
       "      <td>Paroxytone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.941</td>\n",
       "      <td>-1.350</td>\n",
       "      <td>-2.422</td>\n",
       "      <td>-7.537</td>\n",
       "      <td>-12.495</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-6.275</td>\n",
       "      <td>8.291</td>\n",
       "      <td>1.072</td>\n",
       "      <td>14.478</td>\n",
       "      <td>...</td>\n",
       "      <td>215.200</td>\n",
       "      <td>214.568</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.114469</td>\n",
       "      <td>0.398205</td>\n",
       "      <td>1.874521</td>\n",
       "      <td>0.354325</td>\n",
       "      <td>2.058149</td>\n",
       "      <td>Oxytone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>13.362</td>\n",
       "      <td>18.399</td>\n",
       "      <td>17.008</td>\n",
       "      <td>11.790</td>\n",
       "      <td>0.360</td>\n",
       "      <td>2.689</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-5.037</td>\n",
       "      <td>1.391</td>\n",
       "      <td>1.572</td>\n",
       "      <td>...</td>\n",
       "      <td>199.159</td>\n",
       "      <td>201.649</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.110109</td>\n",
       "      <td>0.071348</td>\n",
       "      <td>0.229096</td>\n",
       "      <td>1.349380</td>\n",
       "      <td>0.429277</td>\n",
       "      <td>1.147210</td>\n",
       "      <td>Oxytone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.248</td>\n",
       "      <td>2.999</td>\n",
       "      <td>-12.037</td>\n",
       "      <td>-20.002</td>\n",
       "      <td>-16.433</td>\n",
       "      <td>-11.913</td>\n",
       "      <td>-16.076</td>\n",
       "      <td>19.249</td>\n",
       "      <td>15.037</td>\n",
       "      <td>42.250</td>\n",
       "      <td>...</td>\n",
       "      <td>193.060</td>\n",
       "      <td>192.361</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.116782</td>\n",
       "      <td>0.071910</td>\n",
       "      <td>0.727080</td>\n",
       "      <td>1.511164</td>\n",
       "      <td>0.638038</td>\n",
       "      <td>1.335687</td>\n",
       "      <td>Paroxytone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     H1c_mean_vowel1  H2c_mean_vowel1  H4c_mean_vowel1  A1c_mean_vowel1  \\\n",
       "89            11.870           -2.280           -1.756           -5.440   \n",
       "93             8.287           -0.055           -4.275          -13.221   \n",
       "76             6.941           -1.350           -2.422           -7.537   \n",
       "235           13.362           18.399           17.008           11.790   \n",
       "4             22.248            2.999          -12.037          -20.002   \n",
       "\n",
       "     A2c_mean_vowel1  A3c_mean_vowel1  H2Kc_mean_vowel1  H1H2c_mean_vowel1  \\\n",
       "89           -16.559           -7.019           -17.947             14.150   \n",
       "93           -11.741          -14.051           -11.644              8.341   \n",
       "76           -12.495            0.665            -6.275              8.291   \n",
       "235            0.360            2.689            -0.021             -5.037   \n",
       "4            -16.433          -11.913           -16.076             19.249   \n",
       "\n",
       "     H2H4c_mean_vowel1  H1A1c_mean_vowel1  ...  pF0_mean_vowel2  \\\n",
       "89              -0.524             17.311  ...          219.476   \n",
       "93               4.220             21.508  ...          217.179   \n",
       "76               1.072             14.478  ...          215.200   \n",
       "235              1.391              1.572  ...          199.159   \n",
       "4               15.037             42.250  ...          193.060   \n",
       "\n",
       "     shrF0_mean_vowel2  epoch_mean_vowel2  syl_dur_vowel2  v_dur_vowel2  \\\n",
       "89             217.922              0.206        0.324093      0.061651   \n",
       "93             219.021              0.221        0.251639      0.075995   \n",
       "76             214.568              0.216        0.346100      0.114469   \n",
       "235            201.649              0.194        0.110109      0.071348   \n",
       "4              192.361              0.192        0.116782      0.071910   \n",
       "\n",
       "     sF1_norm_vowel2  sF2_norm_vowel2  pF1_norm_vowel2  pF2_norm_vowel2  \\\n",
       "89          0.491066         1.297863         0.606663         1.605660   \n",
       "93          0.249857         1.852478         0.285118         1.676987   \n",
       "76          0.398205         1.874521         0.354325         2.058149   \n",
       "235         0.229096         1.349380         0.429277         1.147210   \n",
       "4           0.727080         1.511164         0.638038         1.335687   \n",
       "\n",
       "      stress_wd  \n",
       "89   Paroxytone  \n",
       "93   Paroxytone  \n",
       "76      Oxytone  \n",
       "235     Oxytone  \n",
       "4    Paroxytone  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wd.drop(['Filename', 'stress_vowel1', 'stress_vowel2', 'Label_vowel1', 'Label_vowel2',\n",
    "           't1_wd', 't2_wd'],\n",
    "           axis = 1, inplace = True)\n",
    "df_wd.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f249d-336e-40b4-9f9a-0e210ab617cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0f38caf8-d224-4c04-b65c-ef35b7b09a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_leave_one_out(df):\n",
    "    lang = []\n",
    "    partid = []\n",
    "    dfs = []\n",
    "    \n",
    "    for p in df.partID.unique():\n",
    "        part_dicts = []\n",
    "\n",
    "        for l in df.Language.unique():\n",
    "            # isolate language of interest\n",
    "            data = df[df['Language']==l].copy()\n",
    "            data.drop(['Language', 'partID'], axis = 1, inplace = True)\n",
    "            data.reset_index(inplace = True, drop = True)\n",
    "            \n",
    "            # define predictor label\n",
    "            y = data['stress_wd']\n",
    "\n",
    "            # define feature set\n",
    "            X = data.drop(['stress_wd'], axis = 1)\n",
    "            \n",
    "            # subset data\n",
    "            X_nodur = X.drop(['syl_dur_vowel1', 'syl_dur_vowel2',\n",
    "                                 'v_dur_vowel1', 'v_dur_vowel2'], axis = 1)\n",
    "            X_dur_vowel = X.drop(['syl_dur_vowel1', 'syl_dur_vowel2'], axis = 1)\n",
    "            X_dur_syl = X.drop(['v_dur_vowel1', 'v_dur_vowel2'], axis = 1)\n",
    "            X_noformant = X.drop(['sF1_norm_vowel1', 'sF2_norm_vowel1',\n",
    "                                'pF1_norm_vowel1', 'pF2_norm_vowel1'], axis = 1)\n",
    "            \n",
    "            subset_X = [X_noformant, X, X_nodur, X_dur_vowel, X_dur_syl]\n",
    "            col_names = ['noformant', 'formant', 'nodur', 'vowel_dur', 'syl_dur']\n",
    "            \n",
    "            accuracy_list = []\n",
    "            std_list = []\n",
    "            \n",
    "            for X_df, name in zip(subset_X, col_names):\n",
    "                # one-hot encoding\n",
    "                X_df = pd.get_dummies(X_df)\n",
    "\n",
    "                # scale features\n",
    "                X_df = sc.fit_transform(X_df)\n",
    "\n",
    "                # define model and evaluation\n",
    "                model = LDA()\n",
    "                cv = kfold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "                # evaluate baseline model\n",
    "                scores = cross_val_score(model, X_df, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "                accuracy_list.append(mean(scores))\n",
    "                std_list.append(std(scores))\n",
    "        \n",
    "            lda_dict = {'partID': p, 'Language': l, 'Accuracy_noFormants': accuracy_list[0],\n",
    "                'Std_noFormants': std_list[0], 'Accuracy_Formants': accuracy_list[1],\n",
    "               'Std_Formant': std_list[1], 'Accuracy_noDur': accuracy_list[2],\n",
    "                'Std_noDur': std_list[2], 'Accuracy_vowelDur': accuracy_list[3],\n",
    "                'Std_vowelDur': std_list[3], 'Accuracy_sylDur': accuracy_list[4],\n",
    "                'Std_sylDur': std_list[4]}\n",
    "            part_dicts.append(lda_dict)\n",
    "        \n",
    "        # make df for this part and append to df list\n",
    "        part_df = pd.DataFrame.from_dict(part_dicts)\n",
    "        dfs.append(part_df)\n",
    "        \n",
    "    lda_df = pd.concat(dfs)\n",
    "        \n",
    "    return(lda_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0c6602ef-f7a7-4eb3-a4af-4d7e23f13ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Accuracy_noFormants</th>\n",
       "      <th>Std_noFormants</th>\n",
       "      <th>Accuracy_Formants</th>\n",
       "      <th>Std_Formant</th>\n",
       "      <th>Accuracy_noDur</th>\n",
       "      <th>Std_noDur</th>\n",
       "      <th>Accuracy_vowelDur</th>\n",
       "      <th>Std_vowelDur</th>\n",
       "      <th>Accuracy_sylDur</th>\n",
       "      <th>Std_sylDur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lrv099</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.188058</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.172130</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.195013</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.177792</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.187655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lrv099</td>\n",
       "      <td>eng</td>\n",
       "      <td>0.637037</td>\n",
       "      <td>0.183009</td>\n",
       "      <td>0.684444</td>\n",
       "      <td>0.164294</td>\n",
       "      <td>0.589630</td>\n",
       "      <td>0.139338</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.164732</td>\n",
       "      <td>0.650741</td>\n",
       "      <td>0.161467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lrv099</td>\n",
       "      <td>spa</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>0.137325</td>\n",
       "      <td>0.753241</td>\n",
       "      <td>0.146446</td>\n",
       "      <td>0.662963</td>\n",
       "      <td>0.170780</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>0.769907</td>\n",
       "      <td>0.148669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   partID Language  Accuracy_noFormants  Std_noFormants  Accuracy_Formants  \\\n",
       "0  lrv099      cat             0.689286        0.188058           0.658333   \n",
       "1  lrv099      eng             0.637037        0.183009           0.684444   \n",
       "2  lrv099      spa             0.752778        0.137325           0.753241   \n",
       "\n",
       "   Std_Formant  Accuracy_noDur  Std_noDur  Accuracy_vowelDur  Std_vowelDur  \\\n",
       "0     0.172130        0.647619   0.195013           0.673810      0.177792   \n",
       "1     0.164294        0.589630   0.139338           0.620370      0.164732   \n",
       "2     0.146446        0.662963   0.170780           0.722222      0.169270   \n",
       "\n",
       "   Accuracy_sylDur  Std_sylDur  \n",
       "0         0.654167    0.187655  \n",
       "1         0.650741    0.161467  \n",
       "2         0.769907    0.148669  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df = lda_leave_one_out(df_wd)\n",
    "lda_df.head(18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
